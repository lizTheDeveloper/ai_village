{
  "defaultProfile": {
    "name": "Unknown Model",
    "modelPattern": ".*",
    "supportsToolCalling": true,
    "supportsThinkTags": false,
    "supportsReasoningField": false,
    "preferredThinkingFormat": "none",
    "maxContextTokens": 32768,
    "maxOutputTokens": 4096,
    "inputCostPer1M": 1.0,
    "outputCostPer1M": 2.0
  },
  "profiles": [
    {
      "name": "Qwen 3 32B",
      "modelPattern": "qwen[-_]?3[-_.]?32b",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": true,
      "supportsReasoningField": true,
      "preferredThinkingFormat": "think_tags",
      "thinkTagName": "think",
      "maxContextTokens": 32768,
      "maxOutputTokens": 8192,
      "inputCostPer1M": 0.09,
      "outputCostPer1M": 0.09
    },
    {
      "name": "GPT-5.2",
      "modelPattern": "gpt-5\\.2",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": false,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "none",
      "maxContextTokens": 400000,
      "maxOutputTokens": 16384,
      "inputCostPer1M": 2.5,
      "outputCostPer1M": 10.0
    },
    {
      "name": "Claude Sonnet 4.5",
      "modelPattern": "claude[-_\\s]?sonnet[-_\\s]?4[._\\s]5",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": true,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "think_tags",
      "thinkTagName": "thinking",
      "systemPromptSuffix": "\n\nYou may use <thinking>...</thinking> tags for extended reasoning.",
      "maxContextTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPer1M": 3.0,
      "outputCostPer1M": 15.0
    },
    {
      "name": "Gemini 3 Pro",
      "modelPattern": "gemini.*3.*pro",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": false,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "none",
      "maxContextTokens": 2000000,
      "maxOutputTokens": 8192,
      "inputCostPer1M": 1.25,
      "outputCostPer1M": 5.0
    },
    {
      "name": "Kimi K2",
      "modelPattern": "kimi.*k2",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": true,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "think_tags",
      "thinkTagName": "think",
      "maxContextTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPer1M": 0.5,
      "outputCostPer1M": 2.0
    },
    {
      "name": "Llama 3.3",
      "modelPattern": "llama[-_]?3[._]3",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": false,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "none",
      "maxContextTokens": 128000,
      "maxOutputTokens": 8192,
      "inputCostPer1M": 0.06,
      "outputCostPer1M": 0.06
    },
    {
      "name": "DeepSeek V3",
      "modelPattern": "deepseek.*v3",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": true,
      "supportsReasoningField": true,
      "preferredThinkingFormat": "think_tags",
      "thinkTagName": "think",
      "maxContextTokens": 64000,
      "maxOutputTokens": 8192,
      "inputCostPer1M": 0.27,
      "outputCostPer1M": 1.1
    },
    {
      "name": "Mistral Large",
      "modelPattern": "mistral.*large",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": false,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "none",
      "maxContextTokens": 128000,
      "maxOutputTokens": 8192,
      "inputCostPer1M": 2.0,
      "outputCostPer1M": 6.0
    },
    {
      "name": "Qwen (generic)",
      "modelPattern": "qwen",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": true,
      "supportsReasoningField": true,
      "preferredThinkingFormat": "think_tags",
      "thinkTagName": "think",
      "maxContextTokens": 32768,
      "maxOutputTokens": 4096,
      "inputCostPer1M": 0.09,
      "outputCostPer1M": 0.09
    },
    {
      "name": "GPT (generic)",
      "modelPattern": "gpt",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": false,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "none",
      "maxContextTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPer1M": 1.0,
      "outputCostPer1M": 2.0
    },
    {
      "name": "Claude (generic)",
      "modelPattern": "claude",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": true,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "think_tags",
      "thinkTagName": "thinking",
      "maxContextTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPer1M": 3.0,
      "outputCostPer1M": 15.0
    },
    {
      "name": "Llama (generic)",
      "modelPattern": "llama",
      "patternFlags": "i",
      "supportsToolCalling": true,
      "supportsThinkTags": false,
      "supportsReasoningField": false,
      "preferredThinkingFormat": "none",
      "maxContextTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPer1M": 0.06,
      "outputCostPer1M": 0.06
    }
  ]
}
